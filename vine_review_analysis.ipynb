{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Find the latest version of spark 2.0  from http://www-us.apache.org/dist/spark/ and enter as the spark version\n",
    "# For example:\n",
    "# spark_version = 'spark-3.0.0'\n",
    "spark_version = 'spark-3.0.1'\n",
    "os.environ['SPARK_VERSION']=spark_version\n",
    "\n",
    "# Install Spark and Java\n",
    "!apt-get update\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q http://www-us.apache.org/dist/spark/$SPARK_VERSION/$SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!tar xf $SPARK_VERSION-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "# Set Environment Variables\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = f\"/content/{spark_version}-bin-hadoop2.7\"\n",
    "\n",
    "# Start a SparkSession\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start SparkSession\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"vineanalysis\").config(\"spark.driver.extraClassPath\",\"/content/postgresql-42.2.16.jar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data from S3 bucket\n",
    "from pyspark import SparkFiles\n",
    "url = \"https://s3.amazonaws.com/amazon-reviews-pds/tsv/amazon_reviews_us_Video_Games_v1_00.tsv.gz\"\n",
    "spark.sparkContext.addFile(url)\n",
    "df = spark.read.option(\"encoding\", \"UTF-8\").csv(SparkFiles.get(\"amazon_reviews_us_Video_Games_v1_00.tsv.gz\"), sep=\"\\t\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the vine_table. DataFrame\n",
    "vine_df = df.select([\"review_id\", \"star_rating\", \"helpful_votes\", \"total_votes\", \"vine\", \"verified_purchase\"])\n",
    "vine_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for only columns with 20 or more total votes \n",
    "total_votes = vine_df.filter('total_votes>=20')\n",
    "total_votes.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter for only columns with mostly helpful votes\n",
    "helpful_votes_df = total_votes.filter(\"helpful_votes/total_votes>=0.5\")\n",
    "helpful_votes_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in a sql function to use columns \n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filter last DF to only columns with vine == \"Y\" (Paid)\n",
    "paid_helpful_votes = helpful_votes_df.filter(col(\"vine\") == \"Y\")\n",
    "paid_helpful_votes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter last DF to only columns with vine == \"N\" (Unpaid)\n",
    "unpaid_helpful_votes = helpful_votes_df.filter(col(\"vine\") == \"N\")\n",
    "unpaid_helpful_votes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine total number of reviews\n",
    "helpful_votes_df.count()\n",
    "\n",
    "# Determine total number of paid reviews\n",
    "paid_helpful_votes.count()\n",
    "\n",
    "# Determine total number of unpaid reviews\n",
    "unpaid_helpful_votes.count()\n",
    "\n",
    "# Determine number of 5-star reviews\n",
    "helpful_votes_df.filter(col(\"star_rating\") == 5).count()\n",
    "\n",
    "# Determine number of 5-star paid reviews\n",
    "paid_helpful_votes.filter(col(\"star_rating\") == 5).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine number of 5-star unpaid reviews\n",
    "unpaid_helpful_votes.filter(col(\"star_rating\") == 5).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine percentage of 5-star paid reviews\n",
    "count = paid_helpful_votes.count()\n",
    "filtered = paid_helpful_votes.filter(col(\"star_rating\") == 5).count()\n",
    "percent_paid = filtered/count * 100\n",
    "print(str(round(percent_paid,2)) + \"% of paid reviews are 5-stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine percentage of 5-star unpaid reviews\n",
    "count_unpaid = unpaid_helpful_votes.count()\n",
    "filtered_unpaid = unpaid_helpful_votes.filter(col(\"star_rating\") == 5).count()\n",
    "percent_unpaid = filtered_unpaid/count_unpaid * 100\n",
    "print(str(round(percent_unpaid,2)) + \"% of unpaid reviews are 5-stars\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
